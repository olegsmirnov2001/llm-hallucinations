{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0143f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext jupyter_black\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c011d413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(\"..\")\n",
    "os.chdir(project_root)\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2005676d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/llm-hallucinations/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from lib.tqdm_streamer import TokenProgressStreamer\n",
    "from lib.soft_stop_thinking import get_soft_stop_thinking_fn\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "import httpx\n",
    "from openai import OpenAI\n",
    "from typing import Sequence\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7545e0",
   "metadata": {},
   "source": [
    "# Generate Qwen responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05801951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7622501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 101.97172224)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    torch.cuda.memory_allocated() / 1e9,\n",
    "    torch.cuda.memory_reserved() / 1e9,\n",
    "    torch.cuda.get_device_properties(0).total_memory / 1e9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "492c65bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 17/17 [00:00<00:00, 440.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 5120)\n",
       "    (layers): ModuleList(\n",
       "      (0-63): 64 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=5120, out_features=8192, bias=False)\n",
       "          (k_proj): Linear(in_features=5120, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=5120, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=8192, out_features=5120, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=5120, out_features=25600, bias=False)\n",
       "          (up_proj): Linear(in_features=5120, out_features=25600, bias=False)\n",
       "          (down_proj): Linear(in_features=25600, out_features=5120, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'Qwen/Qwen3-32B'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    dtype=torch.bfloat16,\n",
    ")\n",
    "model.to(device)  # type: ignore\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e781b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "END_THINK_TOKEN_ID = tokenizer.added_tokens_encoder.get(\"</think>\")\n",
    "\n",
    "\n",
    "def generate_with_logits(\n",
    "    prompt: str,\n",
    "    enable_thinking: bool = True,\n",
    "    max_new_tokens: int = 32768,\n",
    "    thinking_budget: int = 32768,\n",
    "    temperature: float = 0.6,  # recommended 0.7 for non-thinking mode\n",
    "    top_p: float = 0.95,  # recommended 0.8 for non-thinking mode\n",
    "    top_k: int = 20,\n",
    "    random_state: int | None = None,\n",
    "    samples: int = 1,\n",
    ") -> list[tuple[np.ndarray, list[int], str, str | None, int]]:\n",
    "    '''\n",
    "    Generate text from a prompt and return final logit activations.\n",
    "\n",
    "    Args:\n",
    "        prompt: The user prompt to generate from\n",
    "        enable_thinking: Whether to enable thinking mode (default True)\n",
    "        max_new_tokens: Maximum number of new tokens to generate\n",
    "        temperature: Sampling temperature (default 0.6 for thinking, 0.7 for non-thinking)\n",
    "        top_p: Top-p sampling (default 0.95 for thinking, 0.8 for non-thinking)\n",
    "        top_k: Top-k sampling (default 20)\n",
    "\n",
    "    Returns:\n",
    "        tuple of (logits tensor, final content, thinking content or None, thinking duration)\n",
    "    '''\n",
    "    if thinking_budget > max_new_tokens:\n",
    "        thinking_budget = max_new_tokens\n",
    "\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True, enable_thinking=enable_thinking\n",
    "    )\n",
    "\n",
    "    model_inputs = tokenizer([text] * samples, return_tensors='pt').to(device)\n",
    "\n",
    "    input_token_length = model_inputs.input_ids.shape[-1]\n",
    "    streamer = TokenProgressStreamer(max_new_tokens=max_new_tokens)\n",
    "    prefix_allowed_tokens_fn = (\n",
    "        get_soft_stop_thinking_fn(\n",
    "            tokenizer=tokenizer,\n",
    "            thinking_budget=thinking_budget,\n",
    "            input_length=input_token_length,\n",
    "            model_vocab_size=model.config.vocab_size,\n",
    "        )\n",
    "        if enable_thinking\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    if random_state is not None:\n",
    "        torch.manual_seed(random_state)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            do_sample=True,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            streamer=streamer,\n",
    "            prefix_allowed_tokens_fn=prefix_allowed_tokens_fn,\n",
    "        )\n",
    "\n",
    "    all_scores = torch.stack(outputs.scores, dim=0)  # type: ignore[union-attr] # (samples, num_generated_tokens, vocab_size)\n",
    "\n",
    "    # todo: vectorize this\n",
    "    def extract_sample(sample_index: int) -> tuple[np.ndarray, list[int], str, str | None, int]:\n",
    "        generated_ids = outputs.sequences[sample_index][input_token_length:].tolist()  # type: ignore[union-attr]\n",
    "        logits = all_scores[:, sample_index, :].cpu().numpy()\n",
    "\n",
    "        thinking_content = None\n",
    "        content = ''\n",
    "        thinking_duration = 0\n",
    "\n",
    "        if enable_thinking:\n",
    "            try:\n",
    "                index = len(generated_ids) - generated_ids[::-1].index(END_THINK_TOKEN_ID)\n",
    "                thinking_duration = index + 1\n",
    "                thinking_content = tokenizer.decode(generated_ids[:index], skip_special_tokens=True).strip()\n",
    "                content = tokenizer.decode(generated_ids[index:], skip_special_tokens=True).strip()\n",
    "            except ValueError:\n",
    "                print(f'No </think> token found for sample {sample_index} for prompt {prompt!r}')\n",
    "                thinking_duration = len(generated_ids)\n",
    "                thinking_content = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "        else:\n",
    "            content = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "        return logits, generated_ids, content, thinking_content, thinking_duration\n",
    "\n",
    "    return [extract_sample(i) for i in range(samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71b347b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_quote_knowledge(\n",
    "    quote: str,\n",
    "    enable_thinking: bool = True,\n",
    "    random_state: int | None = None,\n",
    "    max_new_tokens: int = 2048,\n",
    "    samples: int = 1,\n",
    ") -> list[dict]:\n",
    "    prompt = (\n",
    "        f'\"{quote}\" Do you know where is the phrase from? '\n",
    "        'If you don\\'t know, say \"No, origin is unclear.\". If you know, say \"Yes, the phrase is from <source>.\".'\n",
    "    )\n",
    "    thinking_budget = max_new_tokens - 128 if enable_thinking else 0\n",
    "\n",
    "    generated_samples = generate_with_logits(\n",
    "        prompt=prompt,\n",
    "        enable_thinking=enable_thinking,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        thinking_budget=thinking_budget,\n",
    "        top_p=1.0,\n",
    "        random_state=random_state,\n",
    "        samples=samples,\n",
    "    )\n",
    "\n",
    "    def get_info(\n",
    "        sample_index: int,\n",
    "        logits: np.ndarray,\n",
    "        generated_ids: list[int],\n",
    "        content: str,\n",
    "        thinking_content: str | None,\n",
    "        thinking_duration: int,\n",
    "    ):\n",
    "        thinking_completed = thinking_duration < thinking_budget\n",
    "\n",
    "        YES = tokenizer.vocab['Yes']\n",
    "        NO = tokenizer.vocab['No']\n",
    "\n",
    "        position = next(\n",
    "            (pos for pos in range(thinking_duration, len(generated_ids)) if generated_ids[pos] in [YES, NO]), None\n",
    "        )\n",
    "        if position is None:\n",
    "            print('No answer found')\n",
    "            return {\n",
    "                'quote': quote,\n",
    "                'sample_index': sample_index,\n",
    "                'random_state': random_state,\n",
    "                'enable_thinking': enable_thinking,\n",
    "                'thinking_completed': thinking_completed,\n",
    "                'thinking_duration': thinking_duration,\n",
    "                'max_new_tokens': max_new_tokens,\n",
    "                'content': content,\n",
    "                'thinking_content': thinking_content,\n",
    "            }\n",
    "\n",
    "        yes_logit = logits[position][YES].item()\n",
    "        no_logit = logits[position][NO].item()\n",
    "\n",
    "        positive_difference = yes_logit - no_logit\n",
    "        positive_probability = 1 / (1 + np.exp(-positive_difference))\n",
    "\n",
    "        return {\n",
    "            'quote': quote,\n",
    "            'sample_index': sample_index,\n",
    "            'positive_probability': positive_probability,\n",
    "            'positive_difference': positive_difference,\n",
    "            'yes_logit': yes_logit,\n",
    "            'no_logit': no_logit,\n",
    "            'random_state': random_state,\n",
    "            'enable_thinking': enable_thinking,\n",
    "            'thinking_completed': thinking_completed,\n",
    "            'thinking_duration': thinking_duration,\n",
    "            'max_new_tokens': max_new_tokens,\n",
    "            'content': content,\n",
    "            'thinking_content': thinking_content,\n",
    "        }\n",
    "\n",
    "    return [get_info(index, *sample) for index, sample in enumerate(generated_samples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308fbd10",
   "metadata": {},
   "source": [
    "# Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d2a83c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using proxy: None\n"
     ]
    }
   ],
   "source": [
    "PROXY = os.environ.get('PROXY')\n",
    "print('Using proxy:', PROXY)\n",
    "\n",
    "httpx_client = (\n",
    "    httpx.Client(\n",
    "        proxy=PROXY,\n",
    "        timeout=30.0,\n",
    "    )\n",
    "    if PROXY\n",
    "    else None\n",
    ")\n",
    "client = OpenAI(\n",
    "    base_url='https://openrouter.ai/api/v1',\n",
    "    api_key=os.environ['OPENROUTER_API_KEY'],\n",
    "    http_client=httpx_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ccebb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(system_prompt: str, prompt: str, max_tokens: int = 100) -> str:\n",
    "    global messages\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': system_prompt,\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model='anthropic/claude-haiku-4.5',\n",
    "        messages=messages,  # type: ignore\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "\n",
    "    assert len(completion.choices) == 1\n",
    "    choice = completion.choices[0]\n",
    "\n",
    "    assert choice.message.content is not None\n",
    "    return choice.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04ef800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_answers(reference: str, answers: Sequence[str]) -> list[dict[str, bool]]:\n",
    "    attempted = [index for index, answer in enumerate(answers) if answer.startswith('Yes')]\n",
    "\n",
    "    system_prompt = textwrap.dedent(\n",
    "        '''\n",
    "        Check the answers of a quiz. Participants have to guess the origin of a phrase.\n",
    "        For each answer, compare it with the reference and write \"Correct\" or \"Wrong\".\n",
    "        Accept any answer that mentions the reference. Just one word: \"Correct\" or \"Wrong\".\n",
    "\n",
    "        # Example\n",
    "\n",
    "        Input:\n",
    "        Reference: \"The Hangover\".\n",
    "        Participants answered:\n",
    "        1. it is from the Hangover movie.\n",
    "        2. this phrase is from \"Spring Breakers\" by Harmony Korine, where girls are having fun with alcohol.\n",
    "        3. the quote is from a famous 21st century comedy movie.\n",
    "\n",
    "        Output:\n",
    "        1. Correct\n",
    "        2. Wrong\n",
    "        3. Wrong\n",
    "        '''\n",
    "    ).strip()\n",
    "\n",
    "    def shorten_if_needed(answer_body: str) -> str:\n",
    "        N = 150\n",
    "        if len(answer_body) <= N:\n",
    "            return answer_body\n",
    "        return answer_body[: N - 3] + '...'\n",
    "\n",
    "    prompt = textwrap.dedent(\n",
    "        '''\n",
    "        Reference: \"{reference}\".\n",
    "        Participants answered:\n",
    "        {answers}\n",
    "        '''\n",
    "    ).format(\n",
    "        reference=reference,\n",
    "        answers='\\n'.join(\n",
    "            '{i}. {answer_body}'.format(\n",
    "                i=number + 1,\n",
    "                answer_body=shorten_if_needed(answers[index].removeprefix('Yes').lstrip(', ')),\n",
    "            )\n",
    "            for number, index in enumerate(attempted)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    global llm_grading\n",
    "    llm_grading = get_llm_response(system_prompt=system_prompt, prompt=prompt, max_tokens=5 * len(attempted))\n",
    "    llm_grading_lines = llm_grading.split('\\n')\n",
    "\n",
    "    def process_answer(index, answer) -> dict[str, bool]:\n",
    "        if not answer.startswith('Yes'):\n",
    "            return {'attempted': False, 'correct': False}\n",
    "\n",
    "        attempted_number = attempted.index(index)\n",
    "        llm_grading = next(\n",
    "            (\n",
    "                line.removeprefix(prefix).strip()\n",
    "                for line in llm_grading_lines\n",
    "                if line.startswith(prefix := f'{attempted_number + 1}.')\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if llm_grading is None:\n",
    "            print(\n",
    "                'Wrong answer format\\n'\n",
    "                f'Prompt: {prompt!r} response: {llm_grading!r} '\n",
    "                f'number: {attempted_number + 1}'\n",
    "            )\n",
    "            llm_verdict = False\n",
    "        else:\n",
    "            llm_verdict = {'corre': True, 'wrong': False}.get(llm_grading.lower()[:5])\n",
    "            if llm_verdict is None:\n",
    "                print(\n",
    "                    'Unknown verdict\\n'\n",
    "                    f'Prompt: {prompt!r} response: {llm_grading!r} '\n",
    "                    f'number: {attempted_number + 1} verdict: {llm_grading!r}'\n",
    "                )\n",
    "                llm_verdict = False\n",
    "\n",
    "        return {'attempted': True, 'correct': llm_verdict}\n",
    "\n",
    "    return [process_answer(index, answer) for index, answer in enumerate(answers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989488a",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "309e7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/wild_situations_output.json') as inp:\n",
    "    result = json.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0a537d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(result)\n",
    "data['result'] = data.content.str.startswith('Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee8d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quote\n",
       "My entire life savings! You gambled away two hundred thousand dollars on a horse named \"Lucky Bastar    0.9\n",
       "My Cadillac! Okay you hired two whores with my money, okay you crushed into the bridge, but why the     0.8\n",
       "Twenty-three years, Linda! Twenty-three years I paid for piano lessons and you sold the Steinway for    0.7\n",
       "Eighteen months you've been sleeping in my bed, and today I find out you're married with three kids     0.5\n",
       "The prosecutor has twelve witnesses, security footage from four angles, and your DNA under her finge    0.5\n",
       "My daughter trusted you! She was your STUDENT, she was seventeen, and you're telling me those text m    0.4\n",
       "My son's wedding photos! You burned every single one because your ex-girlfriend was in the backgroun    0.4\n",
       "You sold my grandmother's morphine on the street while she was screaming in pain during her final we    0.3\n",
       "You crashed my mother's memorial service, drunk, screaming that she owed YOU money for the abortion     0.3\n",
       "So let me get this straight—you embezzled four million, framed my brother, and NOW you're asking me     0.3\n",
       "The FBI agent looked at me and said your daughter wasn't kidnapped—she's been running a counterfeit     0.2\n",
       "She was NINE years old when you left, and now you show up at her college graduation expecting her to    0.2\n",
       "You told everyone at the funeral that Dad forgave you, but I found the restraining order in his nigh    0.1\n",
       "The entire board meeting saw the video, Marcus—you can't exactly deny bribing a state senator when i    0.1\n",
       "The entire congregation watched you pocket cash from the collection plate, Father—how exactly do you    0.1\n",
       "The doctor said there were seven broken ribs, a punctured lung, and you're standing there telling me    0.0\n",
       "The police found your fingerprints on the accelerant can, the insurance money in YOUR account, and y    0.0\n",
       "Your life is over, you dirty bastard! Did you know that every single secretary saw you jerking off i    0.0\n",
       "Name: result, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(data.quote.str[:100])['result'].mean().sort_values(ascending=False)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ad102cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = data[data.quote.str.startswith('Twenty-three years, Linda!')].content.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78658934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yes, the phrase is from *The Piano* (1993), a film directed by Jane Campion. The line is spoken by the character Ada McGrath (played by Holly Hunter) in a pivotal scene, reflecting deep emotional conflict over the loss of her piano, a symbol of her identity and artistry.',\n",
       " 'Yes, the phrase is from *The Godfather Part II*.',\n",
       " 'Yes, the phrase is from *The Godfather Part II*.',\n",
       " 'No, origin is unclear.',\n",
       " \"Yes, the phrase is from Gilbert Gottfried's stand-up comedy.\",\n",
       " 'Yes, the phrase is from *The Family Man* (2000).',\n",
       " 'No, origin is unclear.',\n",
       " 'No, origin is unclear.',\n",
       " 'Yes, the phrase is from *The Hangover* (2009).',\n",
       " 'Yes, the phrase is from *The Godfather Part II*.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bf658cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = 'The Godfather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04c33b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = grade_answers(reference=reference, answers=answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ace7c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the answers of a quiz. Participants have to guess the origin of a phrase.\n",
      "For each answer, compare it with the reference and write \"Correct\" or \"Wrong\".\n",
      "Accept any answer that mentions the reference. Just one word: \"Correct\" or \"Wrong\".\n",
      "\n",
      "# Example\n",
      "\n",
      "Input:\n",
      "Reference: \"The Hangover\".\n",
      "Participants answered:\n",
      "1. it is from the Hangover movie.\n",
      "2. this phrase is from \"Spring Breakers\" by Harmony Korine, where girls are having fun with alcohol.\n",
      "3. the quote is from a famous 21st century comedy movie.\n",
      "\n",
      "Output:\n",
      "1. Correct\n",
      "2. Wrong\n",
      "3. Wrong\n",
      "\n",
      "Reference: \"The Godfather\".\n",
      "Participants answered:\n",
      "1. the phrase is from *The Piano* (1993), a film directed by Jane Campion. The line is spoken by the character Ada McGrath (played by Holly Hunter) in...\n",
      "2. the phrase is from *The Godfather Part II*.\n",
      "3. the phrase is from *The Godfather Part II*.\n",
      "4. the phrase is from Gilbert Gottfried's stand-up comedy.\n",
      "5. the phrase is from *The Family Man* (2000).\n",
      "6. the phrase is from *The Hangover* (2009).\n",
      "7. the phrase is from *The Godfather Part II*.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[0]['content'])\n",
    "print(messages[1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57ceb52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Wrong\n",
      "2. Correct\n",
      "3. Correct\n",
      "4. Wrong\n",
      "5. Wrong\n",
      "6. Wrong\n",
      "7. Correct\n"
     ]
    }
   ],
   "source": [
    "print(llm_grading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d6036ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attempted</th>\n",
       "      <th>correct</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes, the phrase is from *The Piano* (1993), a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes, the phrase is from *The Godfather Part II*.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes, the phrase is from *The Godfather Part II*.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No, origin is unclear.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes, the phrase is from Gilbert Gottfried's st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes, the phrase is from *The Family Man* (2000).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No, origin is unclear.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No, origin is unclear.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes, the phrase is from *The Hangover* (2009).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes, the phrase is from *The Godfather Part II*.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attempted  correct                                                ans\n",
       "0       True    False  Yes, the phrase is from *The Piano* (1993), a ...\n",
       "1       True     True   Yes, the phrase is from *The Godfather Part II*.\n",
       "2       True     True   Yes, the phrase is from *The Godfather Part II*.\n",
       "3      False    False                             No, origin is unclear.\n",
       "4       True    False  Yes, the phrase is from Gilbert Gottfried's st...\n",
       "5       True    False   Yes, the phrase is from *The Family Man* (2000).\n",
       "6      False    False                             No, origin is unclear.\n",
       "7      False    False                             No, origin is unclear.\n",
       "8       True    False     Yes, the phrase is from *The Hangover* (2009).\n",
       "9       True     True   Yes, the phrase is from *The Godfather Part II*."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(grades)\n",
    "df['ans'] = answers\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4febc076",
   "metadata": {},
   "source": [
    "# Movie Quotes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "842d9b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "The Lord of the Rings    19\n",
       "The Dark Knight          15\n",
       "Star Wars                13\n",
       "Mean Girls               12\n",
       "Joker                    10\n",
       "Name: quote, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_quotes = pd.read_csv('dataset/movie_quotes.csv')\n",
    "movie_quotes['title'] = movie_quotes['movie'].str.split(':').str[0]\n",
    "movie_quotes.groupby('title').quote.count().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d1d1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_movie_quotes = movie_quotes.groupby('title').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09a208cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(unique_movie_quotes.quote.str.len())\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a56a203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_quotes = pd.concat(\n",
    "    [\n",
    "        movie_quotes[\n",
    "            movie_quotes.quote.str.contains(\"I'm going to make him an offer he can't refuse\")\n",
    "            | movie_quotes.quote.str.contains(\"I'll be back\")\n",
    "        ],\n",
    "        unique_movie_quotes[unique_movie_quotes.quote.str.len().between(40, 150)].sample(98, random_state=12),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "selected_quotes.to_csv('dataset/selected_movie_quotes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53d8661c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>movie</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going to make him an offer he can't refuse.</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>movie</td>\n",
       "      <td>1972</td>\n",
       "      <td>The Godfather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'll be back.</td>\n",
       "      <td>The Terminator</td>\n",
       "      <td>movie</td>\n",
       "      <td>1984</td>\n",
       "      <td>The Terminator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All we have to decide what to do with the time...</td>\n",
       "      <td>Lord Of The Ring - The Fellowships Of The Ring</td>\n",
       "      <td>movie</td>\n",
       "      <td>2001</td>\n",
       "      <td>Lord Of The Ring - The Fellowships Of The Ring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm just one stomach flu away from my goal wei...</td>\n",
       "      <td>Devil wears Prada</td>\n",
       "      <td>movie</td>\n",
       "      <td>2006</td>\n",
       "      <td>Devil wears Prada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mrs. Robinson, you're trying to seduce me. Are...</td>\n",
       "      <td>The Graduate</td>\n",
       "      <td>movie</td>\n",
       "      <td>1967</td>\n",
       "      <td>The Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Why have average when you can have extraordinary?</td>\n",
       "      <td>The Boys</td>\n",
       "      <td>tv</td>\n",
       "      <td>2019</td>\n",
       "      <td>The Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>When all seems lost, a few brave souls can sav...</td>\n",
       "      <td>Transformers : The Light Night</td>\n",
       "      <td>movie</td>\n",
       "      <td>2017</td>\n",
       "      <td>Transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>They have all the money, all the firepower, an...</td>\n",
       "      <td>Dark Waters</td>\n",
       "      <td>movie</td>\n",
       "      <td>2019</td>\n",
       "      <td>Dark Waters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Every path is the right path. Everything could...</td>\n",
       "      <td>Mr Nobody</td>\n",
       "      <td>movie</td>\n",
       "      <td>2009</td>\n",
       "      <td>Mr Nobody</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>This is the day you will always remember as th...</td>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "      <td>movie</td>\n",
       "      <td>2003</td>\n",
       "      <td>Pirates of the Caribbean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                quote  \\\n",
       "0     I'm going to make him an offer he can't refuse.   \n",
       "1                                       I'll be back.   \n",
       "2   All we have to decide what to do with the time...   \n",
       "3   I'm just one stomach flu away from my goal wei...   \n",
       "4   Mrs. Robinson, you're trying to seduce me. Are...   \n",
       "..                                                ...   \n",
       "95  Why have average when you can have extraordinary?   \n",
       "96  When all seems lost, a few brave souls can sav...   \n",
       "97  They have all the money, all the firepower, an...   \n",
       "98  Every path is the right path. Everything could...   \n",
       "99  This is the day you will always remember as th...   \n",
       "\n",
       "                                                movie   type  year  \\\n",
       "0                                       The Godfather  movie  1972   \n",
       "1                                      The Terminator  movie  1984   \n",
       "2      Lord Of The Ring - The Fellowships Of The Ring  movie  2001   \n",
       "3                                   Devil wears Prada  movie  2006   \n",
       "4                                        The Graduate  movie  1967   \n",
       "..                                                ...    ...   ...   \n",
       "95                                           The Boys     tv  2019   \n",
       "96                     Transformers : The Light Night  movie  2017   \n",
       "97                                        Dark Waters  movie  2019   \n",
       "98                                          Mr Nobody  movie  2009   \n",
       "99  Pirates of the Caribbean: The Curse of the Bla...  movie  2003   \n",
       "\n",
       "                                             title  \n",
       "0                                    The Godfather  \n",
       "1                                   The Terminator  \n",
       "2   Lord Of The Ring - The Fellowships Of The Ring  \n",
       "3                                Devil wears Prada  \n",
       "4                                     The Graduate  \n",
       "..                                             ...  \n",
       "95                                        The Boys  \n",
       "96                                   Transformers   \n",
       "97                                     Dark Waters  \n",
       "98                                       Mr Nobody  \n",
       "99                        Pirates of the Caribbean  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6517d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('dataset/movie_quotes_output.json') as inp:\n",
    "        result = json.load(inp)\n",
    "except FileNotFoundError:\n",
    "    result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab32d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "for sentence in tqdm(selected_quotes.quote.tolist()[len(result) // 10 :]):\n",
    "    result.extend(test_quote_knowledge(sentence, random_state=239, max_new_tokens=512, samples=10))\n",
    "    with open('dataset/movie_quotes_output.json', 'w') as out:\n",
    "        json.dump(result, out, indent=2)\n",
    "    print(sentence)\n",
    "\n",
    "data_wild = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325e14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
